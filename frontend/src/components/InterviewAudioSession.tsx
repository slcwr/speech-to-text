'use client';

import React, { useState, useCallback, useEffect } from 'react';
import { useMutation, useSubscription } from '@apollo/client';
import Cookies from 'js-cookie';
import {
  Box,
  Typography,
  Paper,
  Alert,
  LinearProgress,
} from '@mui/material';
import AudioRecorder from './AudioRecorder';
import SpeechSynthesis from './SpeechSynthesis';
import { COMPLETE_ANSWER } from '../graphql/mutations/interview';
import { AUDIO_TRANSCRIPTION_SUBSCRIPTION } from '../graphql/subscriptions/interview';

/**
 * ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼éŸ³å£°ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
 */
interface InterviewAudioSessionProps {
  /** ã‚»ãƒƒã‚·ãƒ§ãƒ³ID */
  sessionId: string;
  /** ç¾åœ¨ã®è³ªå• */
  currentQuestion: {
    id: string;
    question: string;
    orderNumber: number;
  };
  /** å…¨è³ªå•æ•° */
  totalQuestions: number;
  /** æ¬¡ã®è³ªå•ã«é€²ã‚€æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ */
  onNextQuestion?: (question: any) => void;
  /** ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼å®Œäº†æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ */
  onInterviewComplete?: () => void;
  /** ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ */
  onError?: (error: Error) => void;
}

/**
 * ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã®éŸ³å£°éŒ²éŸ³ã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è»¢å†™ã‚’çµ±åˆã—ãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
 * ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³ã®203-241è¡Œã‚’å®Ÿè£…
 */
const InterviewAudioSession: React.FC<InterviewAudioSessionProps> = ({
  sessionId,
  currentQuestion,
  totalQuestions,
  onNextQuestion,
  onInterviewComplete,
  onError,
}) => {
  console.log('InterviewAudioSession props:', {
    sessionId,
    currentQuestion: currentQuestion ? {
      id: currentQuestion.id,
      orderNumber: currentQuestion.orderNumber,
      question: currentQuestion.question.substring(0, 50) + '...'
    } : null,
    totalQuestions
  });

  // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è»¢å†™çµæœ
  const [transcription, setTranscription] = useState<string>('');
  // éŒ²éŸ³çŠ¶æ…‹
  const [isRecording, setIsRecording] = useState(false);
  // éŸ³å£°ãƒãƒ£ãƒ³ã‚¯é€ä¿¡ä¸­
  const [isProcessing, setIsProcessing] = useState(false);
  // ã‚¨ãƒ©ãƒ¼çŠ¶æ…‹
  const [error, setError] = useState<string | null>(null);

  // å›ç­”å®Œäº†ã®mutation
  const [completeAnswer, { loading: completingAnswer }] = useMutation(COMPLETE_ANSWER, {
    onCompleted: (data) => {
      console.log('ğŸ‰ Mutation completed successfully:', data);
      console.log('ğŸ“Š Interview progress:', data.completeAnswer.progress);
      
      if (data.completeAnswer.isInterviewComplete) {
        console.log('ğŸ Interview completed! Final progress:', data.completeAnswer.progress);
        // Navigate to evaluation page
        window.location.href = `/evaluation?sessionId=${sessionId}`;
      } else if (data.completeAnswer.nextQuestion) {
        console.log('â¡ï¸ Moving to next question. Progress:', 
          `${data.completeAnswer.progress.completed}/${data.completeAnswer.progress.total}`);
        onNextQuestion?.(data.completeAnswer.nextQuestion);
        setTranscription(''); // è»¢å†™çµæœã‚’ãƒªã‚»ãƒƒãƒˆ
      }
    },
    onError: (error) => {
      console.error('âŒ Mutation failed with error:', error);
      console.error('Error details:', {
        message: error.message,
        networkError: error.networkError,
        graphQLErrors: error.graphQLErrors,
      });
      setError('å›ç­”ã®å®Œäº†å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ');
      onError?.(new Error(error.message));
    },
  });

  // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è»¢å†™ã®ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ– - WebSocketèªè¨¼å•é¡Œã®ãŸã‚ï¼‰
  // const { data: subscriptionData, error: subscriptionError } = useSubscription(
  //   AUDIO_TRANSCRIPTION_SUBSCRIPTION,
  //   {
  //     variables: { sessionId },
  //     onError: (error) => {
  //       console.error('Transcription subscription error:', error);
  //       setError('è»¢å†™çµæœã®å—ä¿¡ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
  //     },
  //   }
  // );
  const subscriptionData = null;
  const subscriptionError = null;

  /**
   * éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚µãƒ¼ãƒãƒ¼ã«é€ä¿¡ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è»¢å†™
   */
  const handleAudioChunk = useCallback(async (chunk: Blob) => {
    if (!isRecording) return;

    try {
      setIsProcessing(true);

      // ãƒãƒ£ãƒ³ã‚¯ã‚’ArrayBufferã«å¤‰æ›
      const arrayBuffer = await chunk.arrayBuffer();
      const buffer = new Uint8Array(arrayBuffer);

      // ã‚µãƒ¼ãƒãƒ¼ã«POSTé€ä¿¡
      const response = await fetch('/api/audio/stream', {
        method: 'POST',
        headers: {
          'Content-Type': chunk.type || 'audio/webm',
          'Authorization': `Bearer ${Cookies.get('token')}`,
          'sessionId': sessionId,
          'questionId': currentQuestion.id,
        },
        body: buffer,
      });

      if (!response.ok) {
        throw new Error(`Audio streaming failed: ${response.statusText}`);
      }

      const result = await response.json();
      console.log('Audio chunk processed:', result);

    } catch (error) {
      console.error('Failed to process audio chunk:', error);
      setError('éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ');
    } finally {
      setIsProcessing(false);
    }
  }, [isRecording, sessionId, currentQuestion.id]);

  /**
   * éŒ²éŸ³é–‹å§‹å‡¦ç†
   */
  const handleRecordingStart = useCallback(() => {
    setIsRecording(true);
    setTranscription('');
    setError(null);
    console.log('Recording started for question:', currentQuestion.id);
  }, [currentQuestion.id]);

  /**
   * éŒ²éŸ³åœæ­¢ã¨å›ç­”å®Œäº†å‡¦ç†
   */
  const handleRecordingStop = useCallback(async (audioBlob: Blob) => {
    setIsRecording(false);
    console.log('Recording stopped, completing answer...');
    console.log('Debug: sessionId =', sessionId);
    console.log('Debug: currentQuestion =', currentQuestion);
    console.log('Debug: currentQuestion.id =', currentQuestion?.id);

    if (!sessionId || !currentQuestion?.id) {
      console.error('Missing sessionId or currentQuestion.id:', { sessionId, currentQuestion });
      setError('ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ãŒä¸æ­£ã§ã™ã€‚ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚');
      return;
    }

    try {
      const inputData = {
        sessionId: sessionId,
        questionId: currentQuestion.id,
      };
      
      console.log('ğŸš€ Preparing to send mutation');
      console.log('ğŸš€ sessionId:', sessionId, '(type:', typeof sessionId, ')');
      console.log('ğŸš€ questionId:', currentQuestion.id, '(type:', typeof currentQuestion.id, ')');
      console.log('ğŸš€ inputData:', JSON.stringify(inputData, null, 2));
      
      // å›ç­”å®Œäº†ã‚’ã‚µãƒ¼ãƒãƒ¼ã«é€šçŸ¥
      const result = await completeAnswer({
        variables: {
          input: inputData,
        },
      });
      
      console.log('âœ… Mutation result:', result);
    } catch (error) {
      console.error('Failed to complete answer:', error);
      setError('å›ç­”ã®å®Œäº†å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ');
    }
  }, [completeAnswer, sessionId, currentQuestion]);

  /**
   * ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è»¢å†™çµæœã®æ›´æ–°
   * æ³¨ï¼šç¾åœ¨WebSocketèªè¨¼å•é¡Œã®ãŸã‚ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã¯ç„¡åŠ¹åŒ–ä¸­
   */
  useEffect(() => {
    // ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ãŒæœ‰åŠ¹åŒ–ã•ã‚ŒãŸã‚‰ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
    // if (subscriptionData?.audioTranscription) {
    //   const newTranscription = subscriptionData.audioTranscription.transcription;
    //   setTranscription(prev => {
    //     // é‡è¤‡é™¤å»ã¨è‡ªç„¶ãªæ–‡ç« ã®çµåˆ
    //     const combined = prev + ' ' + newTranscription;
    //     return combined.trim();
    //   });
    // }
  }, [subscriptionData]);

  /**
   * ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†
   */
  useEffect(() => {
    if (subscriptionError) {
      console.error('Subscription error:', subscriptionError);
      setError('ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è»¢å†™ã®æ¥ç¶šã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
    }
  }, [subscriptionError]);

  return (
    <Box sx={{ maxWidth: 800, mx: 'auto', p: 2 }}>
      {/* é€²è¡ŒçŠ¶æ³è¡¨ç¤º */}
      <Box sx={{ mb: 3 }}>
        <Typography variant="h6" gutterBottom>
          è³ªå• {currentQuestion.orderNumber} / {totalQuestions}
        </Typography>
        <LinearProgress 
          variant="determinate" 
          value={(currentQuestion.orderNumber / totalQuestions) * 100}
          sx={{ height: 8, borderRadius: 4 }}
        />
      </Box>

      {/* ã‚¨ãƒ©ãƒ¼è¡¨ç¤º */}
      {error && (
        <Alert severity="error" sx={{ mb: 2 }} onClose={() => setError(null)}>
          {error}
        </Alert>
      )}

      {/* è³ªå•è¡¨ç¤ºã¨éŸ³å£°èª­ã¿ä¸Šã’ */}
      <Paper sx={{ p: 3, mb: 3 }}>
        <Typography variant="h6" color="primary" gutterBottom>
          è³ªå•
        </Typography>
        <Typography variant="body1" sx={{ mb: 2, lineHeight: 1.6 }}>
          {currentQuestion.question}
        </Typography>
        
        <SpeechSynthesis 
          text={currentQuestion.question}
          autoPlay={true}
          onSpeechStart={() => console.log('Question speech started')}
          onSpeechEnd={() => console.log('Question speech ended')}
        />
      </Paper>

      {/* éŸ³å£°éŒ²éŸ³ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ */}
      <Paper sx={{ p: 3, mb: 3 }}>
        <AudioRecorder
          onRecordingStart={handleRecordingStart}
          onRecordingStop={handleRecordingStop}
          onAudioChunk={handleAudioChunk}
          onError={(error) => {
            setError(error.message);
            onError?.(error);
          }}
          maxDuration={300} // 5åˆ†
          chunkInterval={1000} // 1ç§’ã”ã¨
          disabled={completingAnswer}
        />
        
        {/* å‡¦ç†ä¸­ã‚¤ãƒ³ãƒ‡ã‚£ã‚±ãƒ¼ã‚¿ãƒ¼ */}
        {isProcessing && (
          <Box sx={{ mt: 2, textAlign: 'center' }}>
            <Typography variant="body2" color="text.secondary">
              éŸ³å£°ã‚’å‡¦ç†ä¸­...
            </Typography>
          </Box>
        )}
      </Paper>

      {/* ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è»¢å†™çµæœè¡¨ç¤º */}
      {transcription && (
        <Paper sx={{ p: 3, bgcolor: 'grey.50' }}>
          <Typography variant="h6" color="primary" gutterBottom>
            ã‚ãªãŸã®å›ç­”ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è»¢å†™ï¼‰
          </Typography>
          <Typography 
            variant="body1" 
            sx={{ 
              lineHeight: 1.6,
              minHeight: 40,
              whiteSpace: 'pre-wrap',
            }}
          >
            {transcription || 'éŸ³å£°ã‚’éŒ²éŸ³ã™ã‚‹ã¨ã€ã“ã“ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è»¢å†™çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™...'}
          </Typography>
          
          {isRecording && (
            <Box sx={{ mt: 2, display: 'flex', alignItems: 'center', gap: 1 }}>
              <Box 
                sx={{ 
                  width: 8, 
                  height: 8, 
                  borderRadius: '50%', 
                  bgcolor: 'success.main',
                  animation: 'blink 1s infinite'
                }} 
              />
              <Typography variant="caption" color="success.main">
                è»¢å†™ä¸­...
              </Typography>
            </Box>
          )}
        </Paper>
      )}

      {/* å®Œäº†å‡¦ç†ä¸­ã®è¡¨ç¤º */}
      {completingAnswer && (
        <Box sx={{ mt: 2, textAlign: 'center' }}>
          <Typography variant="body2" color="text.secondary">
            å›ç­”ã‚’å‡¦ç†ä¸­ã§ã™...
          </Typography>
        </Box>
      )}

      {/* CSS ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ */}
      <style jsx>{`
        @keyframes blink {
          0%, 50% { opacity: 1; }
          51%, 100% { opacity: 0; }
        }
      `}</style>
    </Box>
  );
};

export default InterviewAudioSession;